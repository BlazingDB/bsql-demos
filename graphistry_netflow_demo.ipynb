{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kJyD4oSbugE0"
   },
   "source": [
    "# Graphistry Netflow Demo\n",
    "\n",
    "In this notebook, we will: \n",
    "- Set up [BlazingSQL](https://blazingsql.com) and the [RAPIDS AI](https://rapids.ai/) suite.\n",
    "- Query 65M rows of network security data (netflow) with BlazingSQL and then pass to Graphistry to visualize and interact with the data.\n",
    "![Impression](https://www.google-analytics.com/collect?v=1&tid=UA-39814657-5&cid=555&t=event&ec=guides&ea=bsql-quick-start-guide&dt=bsql-quick-start-guide)\n",
    "\n",
    "## Setup\n",
    "### Environment Sanity Check \n",
    "\n",
    "RAPIDS packages (BlazingSQL included) require Pascal+ architecture to run. For Colab, this translates to a T4 GPU instance. \n",
    "\n",
    "The cell below will let you know what type of GPU you've been allocated, and how to proceed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "colab_type": "code",
    "id": "zxhxwrfI7aoT",
    "outputId": "0880eafa-a0b1-4f39-d3dc-bab9d4e8b127"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Woo! You got the right kind of GPU!\n"
     ]
    }
   ],
   "source": [
    "# tag specs\n",
    "colab_smi = !nvidia-smi\n",
    "\n",
    "# focus GPU type\n",
    "try:\n",
    "    my_gpu = ' '.join(colab_smi[7].split()[2:4])\n",
    "# not on gpu acceleration \n",
    "except:\n",
    "    raise Exception(\"\\nPlease make sure you've configured Colab to request a GPU instance type.\\n\\n\"\n",
    "                    \"At top of Colab, try: Runtime -> Change runtime type -> Hardware accelerator -> GPU -> Save\\n\")\n",
    "\n",
    "# not allocated compatable GPU\n",
    "if (my_gpu != b'Tesla T4') and (my_gpu != 'Tesla P100-PCIE...') and (my_gpu != 'GeForce GTX'):\n",
    "    # allocated K80\n",
    "    if my_gpu == 'Tesla K80':\n",
    "        raise Exception(\"\\nYou've been allocated a K80 instance\\n\\n\"\n",
    "                    \"Unfortunately, this demo requires a T4 instance\\n\\n\"\n",
    "                    \"At top of Colab, try: Runtime -> Reset all runtimes...\\n\")\n",
    "    else:\n",
    "        raise Exception(f\"\\nYou've achieved wizardy.\\nyour GPU is {my_gpu}\\nPlease inform info@blazingsql.com\")\n",
    "\n",
    "# allocated compatable GPU\n",
    "else:\n",
    "    print('Woo! You got the right kind of GPU!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installs \n",
    "\n",
    "Below you will find three code blocks:\n",
    "1. The first installs miniconda.\n",
    "2. The second installs RAPIDS AI and sets up the system environment. \n",
    "3. The third installs BlazingSQL.\n",
    "\n",
    "### Miniconda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "a7RprJxtZZtQ",
    "outputId": "5ed256e4-93ee-4295-914d-c5c75c9d6059"
   },
   "outputs": [],
   "source": [
    "# intall miniconda\n",
    "!wget -c https://repo.continuum.io/miniconda/Miniconda3-4.5.4-Linux-x86_64.sh\n",
    "!chmod +x Miniconda3-4.5.4-Linux-x86_64.sh\n",
    "!bash ./Miniconda3-4.5.4-Linux-x86_64.sh -b -f -p /usr/local"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RAPIDS AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "7NnRUE8LZZij",
    "outputId": "0f26273a-1ff7-4039-fa23-1de485e8226d"
   },
   "outputs": [],
   "source": [
    "# install RAPIDS packages\n",
    "!conda install -q -y --prefix /usr/local -c nvidia -c rapidsai \\\n",
    "  -c numba -c conda-forge -c pytorch -c defaults \\\n",
    "  cudf=0.9 cuml=0.9 cugraph=0.9 python=3.6 cudatoolkit=10.0\n",
    "\n",
    "# set environment vars\n",
    "import sys, os, shutil\n",
    "sys.path.append('/usr/local/lib/python3.6/site-packages/')\n",
    "os.environ['NUMBAPRO_NVVM'] = '/usr/local/cuda/nvvm/lib64/libnvvm.so'\n",
    "os.environ['NUMBAPRO_LIBDEVICE'] = '/usr/local/cuda/nvvm/libdevice/'\n",
    "\n",
    "# copy .so files to current working dir\n",
    "for fn in ['libcudf.so', 'librmm.so']:\n",
    "    shutil.copy('/usr/local/lib/'+fn, os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S_0CFcpyo3eo"
   },
   "source": [
    "### BlazingSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install BlazingSQL for CUDA 10.0\n",
    "! conda install -q -y --prefix /usr/local -c conda-forge -c defaults -c nvidia -c rapidsai \\\n",
    "   -c blazingsql/label/cuda10.0 -c blazingsql \\\n",
    "   blazingsql-calcite blazingsql-orchestrator blazingsql-ral blazingsql-python\n",
    "\n",
    "!pip install flatbuffers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4guM6G87ul8e"
   },
   "source": [
    "# Download CSV\n",
    "\n",
    "You will need to download the CSV we are going to use for this demo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 208
    },
    "colab_type": "code",
    "id": "F6teFkVGufUf",
    "outputId": "42fedd97-8baf-4d1a-ea41-95602cd8cb11"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-08-23 21:43:50--  https://blazingsql-colab.s3.amazonaws.com/netflow_data/nf-chunk2.csv\n",
      "Resolving blazingsql-colab.s3.amazonaws.com (blazingsql-colab.s3.amazonaws.com)... 52.216.137.76\n",
      "Connecting to blazingsql-colab.s3.amazonaws.com (blazingsql-colab.s3.amazonaws.com)|52.216.137.76|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 2725056295 (2.5G) [text/csv]\n",
      "Saving to: ‘nf-chunk2.csv’\n",
      "\n",
      "nf-chunk2.csv       100%[===================>]   2.54G  49.2MB/s    in 56s     \n",
      "\n",
      "2019-08-23 21:44:46 (46.2 MB/s) - ‘nf-chunk2.csv’ saved [2725056295/2725056295]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://blazingsql-colab.s3.amazonaws.com/netflow_data/nf-chunk2.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yp7z8bfivbna"
   },
   "source": [
    "#Load & Query Tables\n",
    "\n",
    "Here we are importing cuDF and BlazingSQL. We are then loading the CSV files into a GPU DataFrame (gdf), and then creating tables so that we can run SQL queries on those GDFs. \n",
    "\n",
    "Note, when you create a table off of a GDF there is no copy, it is merely registering the schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OUHKS9Khb76K"
   },
   "outputs": [],
   "source": [
    "# Set Environment Variables\n",
    "\n",
    "import sys, os\n",
    "\n",
    "sys.path.append('/usr/local/lib/python3.6/site-packages/')\n",
    "os.environ['NUMBAPRO_NVVM'] = '/usr/local/cuda/nvvm/lib64/libnvvm.so'\n",
    "os.environ['NUMBAPRO_LIBDEVICE'] = '/usr/local/cuda/nvvm/libdevice/'\n",
    "\n",
    "#Standup the BlazingSQL Services - We are working on removing the need to call these functions and just initializing them in BlazingContext\n",
    "import subprocess\n",
    "subprocess.Popen(['blazingsql-orchestrator', '9100', '8889', '127.0.0.1', '8890'],stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.STDOUT)\n",
    "subprocess.Popen(['java', '-jar', '/usr/local/lib/blazingsql-algebra.jar', '-p', '8890'])\n",
    "import pyblazing.apiv2.context as cont\n",
    "cont.runRal()\n",
    "time.sleep(1) #Wait for service to start."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages and create Blazing Context\n",
    "You can think of the BlazingContext much like a Spark Context (i.e. where information such as FileSystems you have registered and Tables you have created will be stored). If you have issues running this cell, restart runtime and try running it again.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "pqQ8lqL8vb-8",
    "outputId": "4e5ebc46-6319-4d3a-851c-7d6a2ac2825d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connection established\n",
      "CPU times: user 1.91 ms, sys: 13.2 ms, total: 15.1 ms\n",
      "Wall time: 38 ms\n"
     ]
    }
   ],
   "source": [
    "from blazingsql import BlazingContext\n",
    "import cudf\n",
    "\n",
    "bc = BlazingContext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lU-2wlwQntnq"
   },
   "outputs": [],
   "source": [
    "#Load CSVs into GPU DataFrames (gdf)\n",
    "netflow_gdf = cudf.read_csv('/content/nf-chunk2.csv')\n",
    "\n",
    "#Create BlazingSQL Tables - There is no copy in this process\n",
    "bc.create_table('netflow', netflow_gdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cgivbut9df-R"
   },
   "source": [
    "From there we can simply run a SQL query.\n",
    "\n",
    "In this example we are taking millions of rows of netflow (network flow) data in order to search for anomalous activity within a network.\n",
    "\n",
    "We are going to run some joins and aggregations in order to condese these millions of rows into thousands of rows that represent nodes and edges."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x8JSGhf0dZPV"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 277
    },
    "colab_type": "code",
    "id": "umBG2Tp0wbQx",
    "outputId": "b89e3666-f85a-40e9-e7c4-cda9a80b7fe5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  firstSeenSrcIp firstSeenDestIp  ...         lastFlowDate  attemptCount\n",
      "0    172.30.2.60        10.0.0.9  ...  2013-04-03 12:12:37            82\n",
      "1   172.10.1.162       10.0.0.11  ...  2013-04-03 14:58:35            87\n",
      "2   172.10.1.234        10.0.0.5  ...  2013-04-03 15:11:07           104\n",
      "3      10.1.0.76     172.10.1.82  ...  2013-04-03 09:55:05             1\n",
      "4    172.10.1.89        10.0.0.5  ...  2013-04-03 15:17:39           112\n",
      "5   172.30.1.201       172.0.0.1  ...  2013-04-03 23:06:00            29\n",
      "6   172.10.1.106    10.199.250.2  ...  2013-04-03 10:12:35            40\n",
      "7    172.30.1.10       10.0.0.12  ...  2013-04-03 12:11:40            69\n",
      "8    172.20.1.58        10.7.5.5  ...  2013-04-03 11:20:09            49\n",
      "9   172.30.2.125        10.0.0.9  ...  2013-04-03 12:12:37            69\n",
      "\n",
      "[10 rows x 9 columns]\n",
      "CPU times: user 59.7 ms, sys: 10.1 ms, total: 69.7 ms\n",
      "Wall time: 2.28 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sql = '''\n",
    "SELECT\n",
    "  a.firstSeenSrcIp as source,\n",
    "  a.firstSeenDestIp as destination,\n",
    "  count(a.firstSeenDestPort) as targetPorts,\n",
    "  SUM(a.firstSeenSrcTotalBytes) as bytesOut,\n",
    "  SUM(a.firstSeenDestTotalBytes) as bytesIn,\n",
    "  SUM(a.durationSeconds) as durationSeconds,\n",
    "  MIN(parsedDate) as firstFlowDate,\n",
    "  MAX(parsedDate) as lastFlowDate,\n",
    "  COUNT(*) as attemptCount\n",
    "  FROM\n",
    "  main.netflow a\n",
    "  GROUP BY\n",
    "  a.firstSeenSrcIp,\n",
    "  a.firstSeenDestIp\n",
    "  '''\n",
    "\n",
    "result = bc.sql(sql).get()\n",
    "result_gdf = result.columns\n",
    "df = result_gdf.to_pandas()\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qbp_zFmwcNke"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "blazingsql_graphistry_netflow.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
