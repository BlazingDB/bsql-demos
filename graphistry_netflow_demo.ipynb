{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kJyD4oSbugE0"
   },
   "source": [
    "# Graphistry Netflow Demo\n",
    "\n",
    "In this example we are taking millions of rows of netflow (network traffic flow) data in order to search for anomalous activity within a network. We will query 70M+ rows of network security data (netflow) with BlazingSQL and pass it to Graphistry for visualization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blazing Context\n",
    "Here we are importing cuDF and BlazingContext. You can think of the BlazingContext much like a Spark Context (i.e. where information such as FileSystems you have registered and Tables you have created will be stored). If you have issues running this cell, restart runtime and try running it again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already connected to the Orchestrator\n",
      "BlazingContext ready\n"
     ]
    }
   ],
   "source": [
    "from blazingsql import BlazingContext \n",
    "\n",
    "bc = BlazingContext()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yp7z8bfivbna"
   },
   "source": [
    "### Create & Query Tables\n",
    "In this next cell we identify the full path to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/winston/bsql-demos/data/*_0.parquet'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# identify working directory path\n",
    "local_path = !pwd\n",
    "\n",
    "# make wildcard path to load all 4 parquet files into blazingsql\n",
    "path = str(local_path) + '/data/*_0.parquet'\n",
    "\n",
    "# what's the path? \n",
    "path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create\n",
    "Here use the path identified above to load all 4 parquet files into a single BlazingSQL table. This is done by using a wildcard (*) in the file path. \n",
    "\n",
    "Note: point path to `data/small-chunk2.csv` for pre-downloaded data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lU-2wlwQntnq"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.16 ms, sys: 4.18 ms, total: 8.35 ms\n",
      "Wall time: 298 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pyblazing.apiv2.sql.Table at 0x7f7189dc4ac8>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# blazingsql table from gpu dataframe\n",
    "bc.create_table('netflow', path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cgivbut9df-R"
   },
   "source": [
    "#### Query\n",
    "With the table made, we can simply run a SQL query.\n",
    "\n",
    "We are going to run some joins and aggregations in order to condese these millions of rows into thousands of rows that represent nodes and edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 277
    },
    "colab_type": "code",
    "id": "umBG2Tp0wbQx",
    "outputId": "b89e3666-f85a-40e9-e7c4-cda9a80b7fe5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 29.3 ms, sys: 41.9 ms, total: 71.3 ms\n",
      "Wall time: 4.51 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# what are we looking for \n",
    "query = '''\n",
    "        SELECT\n",
    "            a.firstSeenSrcIp as source,\n",
    "            a.firstSeenDestIp as destination,\n",
    "            count(a.firstSeenDestPort) as targetPorts,\n",
    "            SUM(a.firstSeenSrcTotalBytes) as bytesOut,\n",
    "            SUM(a.firstSeenDestTotalBytes) as bytesIn,\n",
    "            SUM(a.durationSeconds) as durationSeconds,\n",
    "            MIN(parsedDate) as firstFlowDate,\n",
    "            MAX(parsedDate) as lastFlowDate,\n",
    "            COUNT(*) as attemptCount\n",
    "        FROM\n",
    "            netflow a\n",
    "        GROUP BY\n",
    "            a.firstSeenSrcIp,\n",
    "            a.firstSeenDestIp\n",
    "        '''\n",
    "\n",
    "# run sql query (returns cuDF DataFrame)\n",
    "gdf = bc.sql(query)\n",
    "\n",
    "# how do the results look?\n",
    "gdf.head(25)"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
